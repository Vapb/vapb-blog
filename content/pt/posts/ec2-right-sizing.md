---
title: "Tipos de inst√¢ncia EC2 e right-sizing"
author: "vapb"
description: "Introdu√ß√£o aos tipos de inst√¢ncia EC2 e ao conceito de right-sizing."
date: 2025-06-26
tags: ["AWS", "EC2"]
toc: true
---

## 1. Introdu√ß√£o

Neste post, vamos entender os tipos de inst√¢ncias EC2, abordar a sele√ß√£o do tipo correto de inst√¢ncia, a pr√°tica do _right-sizing_ e, de forma breve, a ferramenta **AWS Compute Optimizer**.

## 2. Fam√≠lias de inst√¢ncias EC2 da Amazon

A Amazon EC2 oferece mais de **500 tipos de inst√¢ncias**, organizadas em **fam√≠lias** e **subfam√≠lias**. O nome de cada inst√¢ncia indica sua fun√ß√£o e os recursos de hardware dispon√≠veis.

### 2.1. Tipos de inst√¢ncia

Uma inst√¢ncia EC2 √© uma m√°quina virtual (VM) que roda na nuvem da AWS. O tipo de inst√¢ncia determina o hardware do host que ser√° usado. Cada tipo oferece diferentes capacidades de processamento, mem√≥ria e armazenamento, sendo agrupado em fam√≠lias de inst√¢ncia com base nessas caracter√≠sticas.

{{< hint info >}}
**Conceitos importantes:**
- **Inst√¢ncia** = VM na AWS
- **Tipo de inst√¢ncia** = Conjunto de recursos virtuais (CPU, mem√≥ria, etc.)
- **Fam√≠lia de inst√¢ncia** = Conjunto de tipos otimizados para um uso espec√≠fico
- **Subfam√≠lias** = Varia√ß√µes com base no processador ou armazenamento
{{< /hint >}}

## 3. As 5 fam√≠lias de inst√¢ncia da AWS

### 3.1. Uso geral (General Purpose)

Projetadas para oferecer um equil√≠brio entre CPU, mem√≥ria e rede, s√£o a op√ß√£o mais vers√°til para aplica√ß√µes gerais.

#### 3.1.1. Fam√≠lia T (burstable)

Inst√¢ncias com CPU vari√°vel que acumulam cr√©ditos quando ociosas.

{{< details title="Quando usar" >}}
- Workloads com uso de CPU baixo ou vari√°vel
- Aplica√ß√µes que precisam de performance elevada apenas em picos
{{< /details >}}

{{< details title="Como funciona" >}}
Voc√™ ganha **cr√©ditos de CPU** quando a inst√¢ncia est√° abaixo do baseline de CPU e pode us√°-los para ter mais performance durante picos:
- **Modo standard**: se os cr√©ditos acabam, o desempenho √© reduzido ao baseline
- **Modo unlimited**: continua performando acima do baseline, mas voc√™ paga pelo extra usado
{{< /details >}}

#### 3.1.2. Fam√≠lia M (performance constante)

Inst√¢ncias com CPU consistente sem sistema de cr√©ditos.

{{< details title="Quando usar" >}}
- Workloads que precisam de CPU constante e previs√≠vel
- Ambientes de produ√ß√£o cr√≠ticos
- Aplica√ß√µes que usam CPU total continuamente
{{< /details >}}

### 3.2. Otimizadas para processamento (Compute Optimized)

Projetadas com processadores de alto desempenho, essas inst√¢ncias oferecem a maior rela√ß√£o CPU/mem√≥ria entre todas as fam√≠lias, sendo ideais para cargas de trabalho que demandam poder computacional intensivo.

#### 3.2.1. Fam√≠lia C (compute)

Processadores de √∫ltima gera√ß√£o com alto clock, otimizada para cargas CPU-intensive. Melhor custo por vCPU.

{{< details title="Quando usar" >}}
- Aplica√ß√µes "CPU-bound" (limitadas por processamento)
- Workloads que processam dados intensivamente
- Quando CPU √© o recurso cr√≠tico, n√£o mem√≥ria
{{< /details >}}

### 3.3. Otimizadas para mem√≥ria (Memory Optimized)

Projetadas para fornecer grandes quantidades de mem√≥ria RAM em rela√ß√£o aos n√∫cleos de CPU, essas inst√¢ncias s√£o ideais para cargas de trabalho que processam extensos conjuntos de dados na mem√≥ria.

#### 3.3.1. Fam√≠lia R (RAM-optimized)

A mais popular para workloads com alta demanda de mem√≥ria. Oferece **8 GB de RAM por vCPU** (dobro das general purpose).

#### 3.3.2. Fam√≠lia X (extreme memory)

Mem√≥ria extrema com at√© **16 GB de RAM por vCPU** e configura√ß√µes de **4+ TB** por inst√¢ncia.

{{< details title="Quando usar" >}}
- Bancos de dados in-memory massivos (SAP HANA)
- Aplica√ß√µes legacy que n√£o escalam horizontalmente
- Consolida√ß√£o de grandes cargas em poucos servidores
{{< /details >}}

#### 3.3.3. Fam√≠lia z1d (high compute + high memory)

Combina alta frequ√™ncia de CPU (at√© 4.0 GHz) com muita mem√≥ria e NVMe local.

{{< details title="Quando usar" >}}
- Bancos de dados que exigem CPU e mem√≥ria elevadas
- Cargas OLTP de alto volume
- Workloads que precisam de processamento r√°pido e muita RAM
{{< /details >}}

### 3.4. Otimizadas para armazenamento (Storage Optimized)

Projetadas para fornecer armazenamento local de alt√≠ssima performance com acesso sequencial r√°pido e IOPS (opera√ß√µes de entrada/sa√≠da por segundo) extremamente elevados, essas inst√¢ncias s√£o ideais para cargas de trabalho que exigem leitura e grava√ß√£o intensiva de dados.

#### 3.4.1. Fam√≠lia I (I/O intensive)

NVMe SSD local com baix√≠ssima lat√™ncia e milh√µes de IOPS. Inst√¢ncias I4i entregam at√© **60 GB/s** e **400k+ IOPS**.

{{< details title="Quando usar" >}}
- Bancos de dados transacionais de alto volume
- Aplica√ß√µes que precisam de lat√™ncia submilissegundo
- Cargas OLTP cr√≠ticas
{{< /details >}}

#### 3.4.2. Fam√≠lia D (dense storage)

HDD otimizado para throughput sequencial com maior densidade de armazenamento por custo (dezenas de TB por inst√¢ncia).

{{< details title="Quando usar" >}}
- Data lakes
- Arquivos de log hist√≥ricos
- Processamento MapReduce
- Data warehouses com scan sequencial
- Armazenamento massivo local
{{< /details >}}

#### 3.4.3. Fam√≠lia H1 (HDD optimized)

Otimizada para frameworks de big data (Hadoop, Spark) com foco em throughput sequencial.

{{< details title="Quando usar" >}}
- Clusters de processamento distribu√≠do
- Workloads onde custo por TB √© cr√≠tico
- Cen√°rios onde lat√™ncia n√£o √© o principal gargalo
{{< /details >}}

{{< hint warning >}}
**‚ö†Ô∏è Armazenamento ef√™mero**: O storage dessas inst√¢ncias √© local e tempor√°rio (instance store). Se a inst√¢ncia for parada ou encerrada, todos os dados s√£o perdidos. Use EBS ou S3 para persist√™ncia de longo prazo.
{{< /hint >}}

### 3.5. Computa√ß√£o acelerada (Accelerated Computing)

Equipadas com hardware especializado como GPUs, FPGAs ou chips customizados da AWS, essas inst√¢ncias s√£o projetadas para realizar c√°lculos paralelos massivos que seriam ineficientes ou extremamente lentos em CPUs tradicionais.

{{< details title="Quando usar" >}}
- Treinamento e infer√™ncia de modelos de machine learning e deep learning
- Processamento de imagens e v√≠deos em larga escala
- Renderiza√ß√£o 3D e computa√ß√£o gr√°fica
- Simula√ß√µes cient√≠ficas e modelagem computacional
- An√°lise gen√¥mica e bioinform√°tica
- Minera√ß√£o de criptomoedas e c√°lculos de blockchain
- Reconhecimento de padr√µes e processamento de linguagem natural (NLP)
{{< /details >}}

#### 3.5.1. Fam√≠lia P (performance GPU - NVIDIA)

GPUs NVIDIA de alta performance (A100, V100, H100) para treinamento de modelos e computa√ß√£o cient√≠fica.

{{< details title="Quando usar" >}}
- Treinamento de redes neurais profundas
- Pesquisa em IA
- Simula√ß√µes de din√¢mica molecular
- An√°lise de dados cient√≠ficos complexos
{{< /details >}}

#### 3.5.2. Fam√≠lia G (graphics - GPU de prop√≥sito geral)

GPUs NVIDIA (T4, A10G) balanceadas para machine learning e computa√ß√£o gr√°fica.

{{< details title="Quando usar" >}}
- Esta√ß√µes de trabalho virtuais
- Streaming de jogos
- Renderiza√ß√£o de v√≠deo
- Infer√™ncia de modelos de ML em produ√ß√£o
- Aplica√ß√µes que combinam gr√°ficos e IA
{{< /details >}}

#### 3.5.3. Fam√≠lia Inf (AWS Inferentia)

Chips customizados da AWS otimizados exclusivamente para infer√™ncia de modelos ML (n√£o treinamento).

{{< details title="Quando usar" >}}
- Recomenda√ß√£o de produtos
- Classifica√ß√£o de imagens
- Chatbots
- Detec√ß√£o de fraudes
- Deploy de modelos j√° treinados em produ√ß√£o
{{< /details >}}

#### 3.5.4. Fam√≠lia Trn (AWS Trainium)

Chips customizados da AWS para treinamento de deep learning com melhor custo-benef√≠cio que GPUs.

{{< details title="Quando usar" >}}
- Treinamento de modelos de linguagem (LLMs)
- Modelos de vis√£o computacional
- Workloads de treinamento distribu√≠do
{{< /details >}}

#### 3.5.5. Fam√≠lia F (FPGA - Field Programmable Gate Arrays)

FPGAs program√°veis que permitem criar hardware customizado para algoritmos espec√≠ficos.

{{< details title="Quando usar" >}}
- Processamento de dados financeiros de alta frequ√™ncia
- Compress√£o/descompress√£o em tempo real
- Acelera√ß√£o de algoritmos de criptografia
- An√°lise de redes e seguran√ßa
{{< /details >}}

{{< hint warning >}}
**üí∞ Custo elevado**: Essas s√£o as inst√¢ncias mais caras da AWS. Uma √∫nica inst√¢ncia P5 pode custar mais de $30/hora. Certifique-se de que realmente precisa desse poder computacional.
{{< /hint >}}

### 3.6. Como entender os nomes das inst√¢ncias

Exemplo: `m5zn.xlarge`

| Segmento | Significado |
|----------|-------------|
| `m`      | Fam√≠lia: uso geral |
| `5`      | Gera√ß√£o (quanto maior, mais novo) |
| `z`      | Atributo especial: alta frequ√™ncia |
| `n`      | Otimiza√ß√£o de rede |
| `xlarge` | Tamanho da inst√¢ncia |

#### 3.6.1. Tamanhos dispon√≠veis

- Variam de `nano` at√© `32xlarge` (128 vCPUs e 1024 GiB de mem√≥ria)
- Tamanho define recursos de CPU, mem√≥ria, rede e armazenamento

### 3.7. Sufixos comuns

| Sufixo | Significado                           |
|--------|---------------------------------------|
| `a`    | Processador AMD                      |
| `g`    | AWS Graviton                         |
| `i`    | Processador Intel                    |
| `d`    | Armazenamento local (instance store) |
| `n`    | Otimiza√ß√£o de rede                   |
| `b`    | Otimiza√ß√£o para armazenamento em blocos |
| `e`    | Mais mem√≥ria ou armazenamento        |
| `z`    | Alta frequ√™ncia de CPU               |

## 4. Selecionando o tipo correto de inst√¢ncia (right-sizing)

A Amazon EC2 oferece uma grande variedade de tipos de inst√¢ncias, e muitas vezes voc√™ perceber√° que sua carga de trabalho pode rodar bem em diferentes tipos e tamanhos de inst√¢ncia.

O objetivo do _right-sizing_ √© **equilibrar desempenho e custo** com base nas necessidades reais da sua aplica√ß√£o, evitando que a inst√¢ncia fique sobrecarregada ou subutilizada.

### 4.1. Benef√≠cios de novas gera√ß√µes

{{< hint info >}}
**üöÄ Melhor custo-benef√≠cio**: Usar inst√¢ncias de gera√ß√µes mais recentes, com os novos processadores da AWS, pode trazer melhor desempenho e menor custo.
{{< /hint >}}

### 4.2. Alterando a inst√¢ncia conforme a necessidade

Depois de escolher uma inst√¢ncia, **voc√™ n√£o √© obrigado a us√°-la para sempre**. Se sua carga de trabalho mudar, √© poss√≠vel redimensionar a inst√¢ncia, mudando o tipo dela caso esteja sobrecarregada ou subutilizada.

{{< hint warning >}}
**‚ö†Ô∏è Aten√ß√£o ao redimensionar**: Algumas inst√¢ncias permitem troca de tipo com a inst√¢ncia em execu√ß√£o. Outras exigem que a inst√¢ncia seja parada antes da troca. Tamb√©m √© poss√≠vel criar uma nova inst√¢ncia e migrar sua aplica√ß√£o para ela.
{{< /hint >}}

## 5. AWS Compute Optimizer

O **AWS Compute Optimizer** √© uma ferramenta de _right-sizing_ que ajuda a melhorar a efici√™ncia da sua infraestrutura na AWS, fornecendo recomenda√ß√µes de dimensionamento com foco em desempenho e custo.

Ele analisa a configura√ß√£o atual dos seus recursos e suas m√©tricas de utiliza√ß√£o como uso de CPU, mem√≥ria e armazenamento com base nos dados coletados pelo **Amazon CloudWatch** nos √∫ltimos **14 dias**.

{{< details title="Como funciona o Compute Optimizer" >}}
Durante a an√°lise, o servi√ßo identifica padr√µes e caracter√≠sticas espec√≠ficas da carga de trabalho, como:
- Uso intensivo de CPU
- Acessos frequentes a armazenamento local
- Varia√ß√µes de uso ao longo do dia

Com essas informa√ß√µes, o **Compute Optimizer** consegue determinar quais s√£o os recursos de hardware mais adequados para cada workload, sugerindo ajustes que podem reduzir custos e melhorar o desempenho.
{{< /details >}}

{{< hint info >}}
**üí° Sem custo adicional**: O Compute Optimizer n√£o tem custo adicional por padr√£o.
{{< /hint >}}
